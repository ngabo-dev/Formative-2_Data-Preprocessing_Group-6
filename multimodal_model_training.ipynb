{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP31/fGpEoBLhrQdqgL1NDt",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ngabo-dev/Formative-2_Data-Preprocessing_Group-6/blob/main/multimodal_model_training.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "4y5pREU0n0DK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model 1: Facial Recognition Model (Random Forest)"
      ],
      "metadata": {
        "id": "oroR516cZpBV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Description:\n",
        "This model classifies whether a face belongs to a known user or not based on the extracted image features (e.g., histogram, embeddings).\n"
      ],
      "metadata": {
        "id": "zXQo0Nn-Zwtw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b_oLNrpFdPLs",
        "outputId": "fef86d69-1f88-442c-8394-596a3bc861b1"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# List files in your main Drive folder\n",
        "print(os.listdir('/content/drive/MyDrive/'))\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cj2hAgv7dcTR",
        "outputId": "05a6acb0-31d4-481c-9ce5-d6a86534a6fb"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['IRAKOZE Jean Paul    Cohort 1 PART 2 English Proficiency Assessment_January_2023.gdoc', 'IRAKOZE Jean Paul Cohort 1  English Proficiency Assessment_January_2023.gdoc', 'Book report (1).gslides', 'Book report.gslides', 'Essay.gdoc', 'IRAKOZE Jean Paul_cohort 6_negpod 5_Personal Reflection Essay..gdoc', 'Copy of (MAKE A COPY)Articulating Process | Journal -01.gdoc', 'Group discussion_Cohort 6_negport5.gdoc', 'IRAKOZE_Jean Paul_Y1T1 Mission Development [RT_Summative]..gdoc', ' Personal SWOT Workbook_Template [Make a copy].gslides', 'Copy of [Make a copy] Personalized Action Plan (1).gdoc', 'Copy of [Make a copy] Personalized Action Plan.gdoc', 'Copy of Copy of 2020_SP_ALU Resume Template [MAKE A COPY]_v3.gdoc', 'IRAKOZE_Jean Paul_negpod5_Personalized Action Plan.gdoc', 'IRAKOZE Jean Paul_negpod5_Personalized Action Plan.gdoc', 'IRAKOZE Jean Paul.gdoc', 'Irakoze jean paul_Martin Luther King Jr. Recording Sheet.gdoc', 'Untitled document (17).gdoc', 'IRAKOZE Jean Paul- Scavenger Hunt Activity.gdoc', 'Copy of 2020_SP_ALU Resume Template [MAKE A COPY]_v3.gdoc', 'Copy of [Make a Copy] CRAAP Test.gdoc', 'IRAKOZE Jean Paul_SP_ALU Resume Template [MAKE A COPY]_v3.gdoc', 'Copy of [Make a Copy] Building a Starter Portfolio.gslides', 'IRAKOZE Jean Paul Building a Starter Portfolio.gslides', 'Untitled document (16).gdoc', 'process thinking exit baasline', 'articulating purpose', 'Copy of GCGOs.gdoc', 'IRAKOZE Jean Paul CRAAP Test.gdoc', 'ID Card.pdf', 'Key Request.gdoc', 'IRAKOZE Jean Paul_Cohort 6_Negpod 5_Learning Contract Draft.gdoc', 'Untitled document (15).gdoc', 'january intake 2023_E-lab individual reflection_jean paul Irakoze.gdoc', 'Untitled document (14).gdoc', 'IRAKOZE Jean Paul_cohort 6_negpod 5_31032023.gdoc', 'Untitled document (13).gdoc', 'Untitled document (12).gdoc', 'Reflective_Practice_ReconstructionTask_Irakoze_Jean Paul.gdoc', 'Irakoze_Jean Paul_mission Development_Y1T1 [reflective thinking].gdoc', 'learning processes_summatives..gdoc', 'Untitled document (11).gdoc', 'Untitled document (10).gdoc', 'Copy of Untitled document.gdoc', 'exit baselines', 'Untitled document (9).gdoc', 'ALU Undergraduate Coaching Agreement 2023.pdf', 'Research methodology assignment IV.gdoc', 'Python3: Mutable, Immutable.gdoc', 'RESEARCH-METHODOLOGY assignment 05.gdoc', 'FACTURE (3).pdf', 'FACTURE (2).pdf', 'Leadership Manifesto_Irakoze Jean Paul..gdoc', 'Copy of project plan.gslides', 'Computer Architecture assignment.gdoc', 'exit-baselines', 'Brochure_CMU-DELE_03-05-2023_V12.pdf', ' Travel the Rwanda.gdoc', 'Copy of [Make a copy] Responsible Enterprise_Design Worksheet_2022.gslides', 'Untitled document (8).gdoc', 'Untitled document (7).gdoc', 'approval.pdf', 'Group 5 English assignment.gdoc', '2023_12_ALU RW Student Terms and Conditions pdf.pdf', 'FACTURE (1).pdf', 'FACTURE.pdf', 'Irakoze Jean Paul updated cv (1).pdf', 'Irakoze Jean Paul updated cv.pdf', 'Untitled document (6).gdoc', 'Irakoze Jean Paul 2024 cv (1).docx', 'Irakoze Jean Paul - CV - 6 Mar 2024.pdf', 'j8jwYq7cv8CFBU3kKYfMb4j060PyH51r+HID1Crqh+w=.enc.tmp', 'Irakoze Jean Paul 2024 cv.pdf', '2023 September Term (ALU) - Statement of Progression - Jean Paul Irakoze.pdf', 'Untitled document (5).gdoc', 'Untitled document (4).gdoc', 'RESEARCH PROJECT.gdoc', 'certificate-global-fintech-fundamentals-elevand.pdf', 'Untitled document (3).gdoc', 'IRAKOZE Certificate high school Diploma.pdf', 'Familymembers.pdf', 'Household Monthly Income.pdf', 'Internship-letter_MINICOFIN.gdoc', 'IRAKOZE Jean Paul_[Assignment1]_[W1]_[05-23-2024].docx', 'Irakoze Jean Paul 2024 cv.docx', 'IRAKOZE Jean-paul_[Assignment2]_[W3]-[06-01-2024].gdoc', 'Copy of (MAKE A COPY) Logbook | Skills Immersion 2 | 2024 January Term.gsheet', 'Untitled document (2).gdoc', 'Copy of 2024M Kuza Initiatives OKrs template.gdoc', 'facture 2.JPG', \"Juru's Internship report letter.gdoc\", 'PLD3_StandUp_1_Assignment.gdoc', 'IRAKOZE Jean-paul_[Assignment4]-[06-20-2024].gdoc', 'Jean Paul IRAKOZE_[Summative]_[08-02-2024].gdoc', 'lv_0_20240802212734.mp4', 'Alusive grant (1).pdf', 'Alusive grant.pdf', 'Irakoze Jean Paul  Alusive Grant Agreement (1).pdf', 'Irakoze Jean Paul  Alusive Grant Agreement.pdf', 'WhatsApp Image 2024-09-05 at 16.24.57.jpeg', 'WhatsApp Image 2024-09-05 at 16.27.34.jpeg', 'IRAKOZE Jean Paul Logbook | VIS | Skills Immersion | 2024S  (1).gsheet', 'IRAKOZE_Jean-Paul[Assignment2]_[W3]_[09-19-2024].gdoc', 'Screenshot_20240923-111537_WhatsApp (1).jpg', 'Screenshot_20240923-111537_WhatsApp.jpg', 'Copy of  (MAKE A COPY) Logbook | VIS | Skills Immersion | 2024S .gsheet', 'IRAKOZE_Jean Paul[Assignment1]_[W1]_[13-09-2024].docx', 'TutorConnect User Research Summary.gdoc', 'IRAKOZE_Jean-Paul[Assignment4]_[10-13-2024].gdoc', 'Copy of 2024S Circle Tactical Meeting Template .gdoc', 'FOR IMMEDIATE RELEASE.gdoc', 'Artifact 1: [tutorConnect -  Jean-Paul IRAKOZE].gdoc', 'Untitled document (1).gdoc', 'IRAKOZE Jean Paul Logbook | VIS | Skills Immersion | 2024S .gsheet', 'IRAKOZE Jean Paul Logbook | VIS | Skills Immersion | 2024.gsheet', 'IRAKOZE Jean-Paul_[Summative]_[11-25-2024].gdoc', 'Copy of Brian & Tamanda_[BSE] Mathematics For Machine Learning: Calculus Student Activity (1).gslides', 'Copy of Brian & Tamanda_[BSE] Mathematics For Machine Learning: Calculus Student Activity.gslides', ' Jean Paul IRAKOZE [BSE] Mathematics For Machine Learning: Calculus In-class Activity.gslides', 'Screen-Demo.mov', 'IRAKOZE Jean Paul [App_Demo].gdoc', 'ATTENDENCE LIST OF NETWORKING.docx', 'Copy of Summative Assignment.ipynb', 'Colab Notebooks', 'Optimization with multiple variables', '.ipynb_checkpoints', 'internet_speed_dataset.csv', 'Screen Recording 2025-04-03 at 20.29.15.mov', 'Activity and Sequence diagram .gdoc', 'Copy of Lean Canvas Template.gslides', 'IRAKOZE Formative 1 - Proposal Writing Template - introduction to Machine Learning  .gdoc', 'water_potability.csv', 'ML_Dropout_Project', 'saved_models', 'Untitled document.gdoc', 'Autemated data augementation.gdoc', 'audio_features.csv', 'customer_social_profiles.csv', 'image_features.csv', 'merged_engineered_data.csv']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# Set the folder path (adjust if your files are in a subfolder)\n",
        "folder_path = '/content/drive/MyDrive/'\n",
        "\n",
        "# List and print each file vertically\n",
        "for file in os.listdir(folder_path):\n",
        "    print(file)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R9_rj25Cdqq1",
        "outputId": "aec6a504-4323-4045-fd11-b8fa17b6e7d2"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "IRAKOZE Jean Paul    Cohort 1 PART 2 English Proficiency Assessment_January_2023.gdoc\n",
            "IRAKOZE Jean Paul Cohort 1  English Proficiency Assessment_January_2023.gdoc\n",
            "Book report (1).gslides\n",
            "Book report.gslides\n",
            "Essay.gdoc\n",
            "IRAKOZE Jean Paul_cohort 6_negpod 5_Personal Reflection Essay..gdoc\n",
            "Copy of (MAKE A COPY)Articulating Process | Journal -01.gdoc\n",
            "Group discussion_Cohort 6_negport5.gdoc\n",
            "IRAKOZE_Jean Paul_Y1T1 Mission Development [RT_Summative]..gdoc\n",
            " Personal SWOT Workbook_Template [Make a copy].gslides\n",
            "Copy of [Make a copy] Personalized Action Plan (1).gdoc\n",
            "Copy of [Make a copy] Personalized Action Plan.gdoc\n",
            "Copy of Copy of 2020_SP_ALU Resume Template [MAKE A COPY]_v3.gdoc\n",
            "IRAKOZE_Jean Paul_negpod5_Personalized Action Plan.gdoc\n",
            "IRAKOZE Jean Paul_negpod5_Personalized Action Plan.gdoc\n",
            "IRAKOZE Jean Paul.gdoc\n",
            "Irakoze jean paul_Martin Luther King Jr. Recording Sheet.gdoc\n",
            "Untitled document (17).gdoc\n",
            "IRAKOZE Jean Paul- Scavenger Hunt Activity.gdoc\n",
            "Copy of 2020_SP_ALU Resume Template [MAKE A COPY]_v3.gdoc\n",
            "Copy of [Make a Copy] CRAAP Test.gdoc\n",
            "IRAKOZE Jean Paul_SP_ALU Resume Template [MAKE A COPY]_v3.gdoc\n",
            "Copy of [Make a Copy] Building a Starter Portfolio.gslides\n",
            "IRAKOZE Jean Paul Building a Starter Portfolio.gslides\n",
            "Untitled document (16).gdoc\n",
            "process thinking exit baasline\n",
            "articulating purpose\n",
            "Copy of GCGOs.gdoc\n",
            "IRAKOZE Jean Paul CRAAP Test.gdoc\n",
            "ID Card.pdf\n",
            "Key Request.gdoc\n",
            "IRAKOZE Jean Paul_Cohort 6_Negpod 5_Learning Contract Draft.gdoc\n",
            "Untitled document (15).gdoc\n",
            "january intake 2023_E-lab individual reflection_jean paul Irakoze.gdoc\n",
            "Untitled document (14).gdoc\n",
            "IRAKOZE Jean Paul_cohort 6_negpod 5_31032023.gdoc\n",
            "Untitled document (13).gdoc\n",
            "Untitled document (12).gdoc\n",
            "Reflective_Practice_ReconstructionTask_Irakoze_Jean Paul.gdoc\n",
            "Irakoze_Jean Paul_mission Development_Y1T1 [reflective thinking].gdoc\n",
            "learning processes_summatives..gdoc\n",
            "Untitled document (11).gdoc\n",
            "Untitled document (10).gdoc\n",
            "Copy of Untitled document.gdoc\n",
            "exit baselines\n",
            "Untitled document (9).gdoc\n",
            "ALU Undergraduate Coaching Agreement 2023.pdf\n",
            "Research methodology assignment IV.gdoc\n",
            "Python3: Mutable, Immutable.gdoc\n",
            "RESEARCH-METHODOLOGY assignment 05.gdoc\n",
            "FACTURE (3).pdf\n",
            "FACTURE (2).pdf\n",
            "Leadership Manifesto_Irakoze Jean Paul..gdoc\n",
            "Copy of project plan.gslides\n",
            "Computer Architecture assignment.gdoc\n",
            "exit-baselines\n",
            "Brochure_CMU-DELE_03-05-2023_V12.pdf\n",
            " Travel the Rwanda.gdoc\n",
            "Copy of [Make a copy] Responsible Enterprise_Design Worksheet_2022.gslides\n",
            "Untitled document (8).gdoc\n",
            "Untitled document (7).gdoc\n",
            "approval.pdf\n",
            "Group 5 English assignment.gdoc\n",
            "2023_12_ALU RW Student Terms and Conditions pdf.pdf\n",
            "FACTURE (1).pdf\n",
            "FACTURE.pdf\n",
            "Irakoze Jean Paul updated cv (1).pdf\n",
            "Irakoze Jean Paul updated cv.pdf\n",
            "Untitled document (6).gdoc\n",
            "Irakoze Jean Paul 2024 cv (1).docx\n",
            "Irakoze Jean Paul - CV - 6 Mar 2024.pdf\n",
            "j8jwYq7cv8CFBU3kKYfMb4j060PyH51r+HID1Crqh+w=.enc.tmp\n",
            "Irakoze Jean Paul 2024 cv.pdf\n",
            "2023 September Term (ALU) - Statement of Progression - Jean Paul Irakoze.pdf\n",
            "Untitled document (5).gdoc\n",
            "Untitled document (4).gdoc\n",
            "RESEARCH PROJECT.gdoc\n",
            "certificate-global-fintech-fundamentals-elevand.pdf\n",
            "Untitled document (3).gdoc\n",
            "IRAKOZE Certificate high school Diploma.pdf\n",
            "Familymembers.pdf\n",
            "Household Monthly Income.pdf\n",
            "Internship-letter_MINICOFIN.gdoc\n",
            "IRAKOZE Jean Paul_[Assignment1]_[W1]_[05-23-2024].docx\n",
            "Irakoze Jean Paul 2024 cv.docx\n",
            "IRAKOZE Jean-paul_[Assignment2]_[W3]-[06-01-2024].gdoc\n",
            "Copy of (MAKE A COPY) Logbook | Skills Immersion 2 | 2024 January Term.gsheet\n",
            "Untitled document (2).gdoc\n",
            "Copy of 2024M Kuza Initiatives OKrs template.gdoc\n",
            "facture 2.JPG\n",
            "Juru's Internship report letter.gdoc\n",
            "PLD3_StandUp_1_Assignment.gdoc\n",
            "IRAKOZE Jean-paul_[Assignment4]-[06-20-2024].gdoc\n",
            "Jean Paul IRAKOZE_[Summative]_[08-02-2024].gdoc\n",
            "lv_0_20240802212734.mp4\n",
            "Alusive grant (1).pdf\n",
            "Alusive grant.pdf\n",
            "Irakoze Jean Paul  Alusive Grant Agreement (1).pdf\n",
            "Irakoze Jean Paul  Alusive Grant Agreement.pdf\n",
            "WhatsApp Image 2024-09-05 at 16.24.57.jpeg\n",
            "WhatsApp Image 2024-09-05 at 16.27.34.jpeg\n",
            "IRAKOZE Jean Paul Logbook | VIS | Skills Immersion | 2024S  (1).gsheet\n",
            "IRAKOZE_Jean-Paul[Assignment2]_[W3]_[09-19-2024].gdoc\n",
            "Screenshot_20240923-111537_WhatsApp (1).jpg\n",
            "Screenshot_20240923-111537_WhatsApp.jpg\n",
            "Copy of  (MAKE A COPY) Logbook | VIS | Skills Immersion | 2024S .gsheet\n",
            "IRAKOZE_Jean Paul[Assignment1]_[W1]_[13-09-2024].docx\n",
            "TutorConnect User Research Summary.gdoc\n",
            "IRAKOZE_Jean-Paul[Assignment4]_[10-13-2024].gdoc\n",
            "Copy of 2024S Circle Tactical Meeting Template .gdoc\n",
            "FOR IMMEDIATE RELEASE.gdoc\n",
            "Artifact 1: [tutorConnect -  Jean-Paul IRAKOZE].gdoc\n",
            "Untitled document (1).gdoc\n",
            "IRAKOZE Jean Paul Logbook | VIS | Skills Immersion | 2024S .gsheet\n",
            "IRAKOZE Jean Paul Logbook | VIS | Skills Immersion | 2024.gsheet\n",
            "IRAKOZE Jean-Paul_[Summative]_[11-25-2024].gdoc\n",
            "Copy of Brian & Tamanda_[BSE] Mathematics For Machine Learning: Calculus Student Activity (1).gslides\n",
            "Copy of Brian & Tamanda_[BSE] Mathematics For Machine Learning: Calculus Student Activity.gslides\n",
            " Jean Paul IRAKOZE [BSE] Mathematics For Machine Learning: Calculus In-class Activity.gslides\n",
            "Screen-Demo.mov\n",
            "IRAKOZE Jean Paul [App_Demo].gdoc\n",
            "ATTENDENCE LIST OF NETWORKING.docx\n",
            "Copy of Summative Assignment.ipynb\n",
            "Colab Notebooks\n",
            "Optimization with multiple variables\n",
            ".ipynb_checkpoints\n",
            "internet_speed_dataset.csv\n",
            "Screen Recording 2025-04-03 at 20.29.15.mov\n",
            "Activity and Sequence diagram .gdoc\n",
            "Copy of Lean Canvas Template.gslides\n",
            "IRAKOZE Formative 1 - Proposal Writing Template - introduction to Machine Learning  .gdoc\n",
            "water_potability.csv\n",
            "ML_Dropout_Project\n",
            "saved_models\n",
            "Untitled document.gdoc\n",
            "Autemated data augementation.gdoc\n",
            "audio_features.csv\n",
            "customer_social_profiles.csv\n",
            "image_features.csv\n",
            "merged_engineered_data.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 215
        },
        "id": "LZea5yIPbel6",
        "outputId": "c9a2b22b-0e8b-4443-d7b7-568fe36193af"
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-18180d6b-c30a-41ad-ac44-f4329213754e\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-18180d6b-c30a-41ad-ac44-f4329213754e\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving audio_features.csv to audio_features.csv\n",
            "Saving customer_social_profiles.csv to customer_social_profiles.csv\n",
            "Saving customer_transactions.csv to customer_transactions.csv\n",
            "Saving image_features (1).csv to image_features (1) (3).csv\n",
            "Saving merged_engineered_data.csv to merged_engineered_data.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(image_df.columns.tolist())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vowlTVXpfaMJ",
        "outputId": "551d6f9f-0a32-4fa5-fa47-5689bdc4abe9"
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['member_name', 'expression', 'augmentation_type', 'image_path', 'height', 'width', 'aspect_ratio', 'total_pixels', 'blue_mean', 'blue_std', 'blue_min', 'blue_max', 'blue_median', 'green_mean', 'green_std', 'green_min', 'green_max', 'green_median', 'red_mean', 'red_std', 'red_min', 'red_max', 'red_median', 'hue_mean', 'hue_std', 'saturation_mean', 'saturation_std', 'value_mean', 'value_std', 'gray_mean', 'gray_std', 'gray_min', 'gray_max', 'gray_median', 'blue_hist_0', 'blue_hist_1', 'blue_hist_2', 'blue_hist_3', 'blue_hist_4', 'blue_hist_5', 'blue_hist_6', 'blue_hist_7', 'blue_hist_8', 'blue_hist_9', 'blue_hist_10', 'blue_hist_11', 'blue_hist_12', 'blue_hist_13', 'blue_hist_14', 'blue_hist_15', 'green_hist_0', 'green_hist_1', 'green_hist_2', 'green_hist_3', 'green_hist_4', 'green_hist_5', 'green_hist_6', 'green_hist_7', 'green_hist_8', 'green_hist_9', 'green_hist_10', 'green_hist_11', 'green_hist_12', 'green_hist_13', 'green_hist_14', 'green_hist_15', 'red_hist_0', 'red_hist_1', 'red_hist_2', 'red_hist_3', 'red_hist_4', 'red_hist_5', 'red_hist_6', 'red_hist_7', 'red_hist_8', 'red_hist_9', 'red_hist_10', 'red_hist_11', 'red_hist_12', 'red_hist_13', 'red_hist_14', 'red_hist_15', 'gray_hist_0', 'gray_hist_1', 'gray_hist_2', 'gray_hist_3', 'gray_hist_4', 'gray_hist_5', 'gray_hist_6', 'gray_hist_7', 'gray_hist_8', 'gray_hist_9', 'gray_hist_10', 'gray_hist_11', 'gray_hist_12', 'gray_hist_13', 'gray_hist_14', 'gray_hist_15', 'sobel_mean_x', 'sobel_mean_y', 'sobel_std_x', 'sobel_std_y', 'sobel_max_x', 'sobel_max_y', 'edge_density', 'edge_count', 'laplacian_variance', 'num_faces_detected', 'face_x', 'face_y', 'face_width', 'face_height', 'face_area', 'face_aspect_ratio', 'face_center_x', 'face_center_y', 'face_gray_mean', 'face_gray_std', 'face_blue_mean', 'face_blue_std', 'face_green_mean', 'face_green_std', 'face_red_mean', 'face_red_std']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "!"
      ],
      "metadata": {
        "id": "u3y2JK-wzB89"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Facial Recognition Model (Random Forest)"
      ],
      "metadata": {
        "id": "5KNTegyDzGr5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile models/facial_model.py\n",
        "# models/facial_model.py\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "import joblib\n",
        "import os\n",
        "\n",
        "def train_facial_model():\n",
        "    df = pd.read_csv(\"image_features.csv\")\n",
        "\n",
        "    label_col = 'member_name'  # use actual column name from your dataset\n",
        "\n",
        "    # Validate label column presence\n",
        "    if label_col not in df.columns:\n",
        "        raise KeyError(f\"The '{label_col}' column is missing in the image_features.csv\")\n",
        "\n",
        "    # Drop rows with missing label values\n",
        "    df = df.dropna(subset=[label_col])\n",
        "\n",
        "    # Encode label column (target)\n",
        "    label_encoder = LabelEncoder()\n",
        "    df[label_col] = label_encoder.fit_transform(df[label_col])\n",
        "\n",
        "    # Separate features and labels\n",
        "    X = df.drop(columns=[label_col])\n",
        "    y = df[label_col]\n",
        "\n",
        "    # Encode any non-numeric feature columns\n",
        "    for col in X.columns:\n",
        "        if X[col].dtype == 'object':\n",
        "            X[col] = LabelEncoder().fit_transform(X[col])\n",
        "\n",
        "    # Split data\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "    # Train model\n",
        "    model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "    model.fit(X_train, y_train)\n",
        "\n",
        "    # Save model and label encoder\n",
        "    os.makedirs(\"saved_models\", exist_ok=True)\n",
        "    joblib.dump(model, \"saved_models/facial_model.pkl\")\n",
        "    joblib.dump(label_encoder, \"saved_models/facial_label_encoder.pkl\")\n",
        "\n",
        "    print(\"‚úÖ Facial recognition model trained and saved successfully!\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    train_facial_model()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yG4CSD_TxWCm",
        "outputId": "0801f072-2a36-42fc-94c2-996a32b2039f"
      },
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting models/facial_model.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python3 models/facial_model.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dQpp_JDh4gIF",
        "outputId": "444b1315-d6e5-4a9d-fa5c-5cb3a22ba6c2"
      },
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Facial recognition model trained and saved successfully!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Audio Recognition Model (Random Forest)"
      ],
      "metadata": {
        "id": "11DdsODzzJ4p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile models/voice_model.py\n",
        "# Voiceprint Verification Model - Random Forest\n",
        "\n",
        "import pandas as pd\n",
        "import os\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import joblib\n",
        "\n",
        "def train_voice_model():\n",
        "    df = pd.read_csv(\"/content/drive/MyDrive/audio_features.csv\")\n",
        "\n",
        "    # ‚úÖ Extract label from filename (e.g. 'john_01.wav' -> 'john')\n",
        "    if 'filename' not in df.columns:\n",
        "        raise KeyError(\"The 'filename' column is missing in audio_features.csv\")\n",
        "\n",
        "    df['label'] = df['filename'].apply(lambda x: os.path.basename(x).split('_')[0])\n",
        "\n",
        "    # ‚úÖ Encode label\n",
        "    le = LabelEncoder()\n",
        "    df['label'] = le.fit_transform(df['label'])\n",
        "\n",
        "    # ‚úÖ Features (drop filename and label)\n",
        "    X = df.drop(columns=['filename', 'label'])\n",
        "\n",
        "    # ‚úÖ Handle non-numeric types in features\n",
        "    for col in X.columns:\n",
        "        if X[col].dtype == 'object':\n",
        "            X[col] = LabelEncoder().fit_transform(X[col])\n",
        "\n",
        "    y = df['label']\n",
        "\n",
        "    # ‚úÖ Split\n",
        "    X_train, X_test, y_train, y_test = train_test_split(\n",
        "        X, y, test_size=0.2, random_state=42\n",
        "    )\n",
        "\n",
        "    # ‚úÖ Train\n",
        "    model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "    model.fit(X_train, y_train)\n",
        "\n",
        "    # ‚úÖ Report\n",
        "    y_pred = model.predict(X_test)\n",
        "    print(\"üé§ Voice Recognition Model Report:\")\n",
        "    print(classification_report(y_test, y_pred, target_names=le.classes_))\n",
        "\n",
        "    # ‚úÖ Save\n",
        "    os.makedirs(\"saved_models\", exist_ok=True)\n",
        "    joblib.dump(model, \"saved_models/voice_model.pkl\")\n",
        "    joblib.dump(le, \"saved_models/voice_label_encoder.pkl\")\n",
        "\n",
        "    print(\"‚úÖ Voice model trained and saved successfully.\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    train_voice_model()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iq5CtGaozRCs",
        "outputId": "07746868-f74f-4456-adad-1b8f05d1136f"
      },
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting models/voice_model.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python3 models/voice_model.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fwakucqJ4lKq",
        "outputId": "18018bae-bf69-42f9-8bdd-2111f60e1191"
      },
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üé§ Voice Recognition Model Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        omar       1.00      1.00      1.00         1\n",
            "\n",
            "    accuracy                           1.00         1\n",
            "   macro avg       1.00      1.00      1.00         1\n",
            "weighted avg       1.00      1.00      1.00         1\n",
            "\n",
            "‚úÖ Voice model trained and saved successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "df = pd.read_csv(\"/content/drive/MyDrive/audio_features.csv\")\n",
        "print(df.columns.tolist())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j3fJKGHN595P",
        "outputId": "6253ac53-c781-4019-d90f-0ad0497c3e9b"
      },
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['mfccs', 'rolloff', 'energy', 'filename']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Product Recognition Model (Random Forest)"
      ],
      "metadata": {
        "id": "KqkEy9sAz-yZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile models/product_model.py\n",
        "\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "from sklearn.metrics import classification_report\n",
        "import joblib\n",
        "import os\n",
        "\n",
        "def train_product_model():\n",
        "    # Load data\n",
        "    df = pd.read_csv(\"merged_engineered_data.csv\")  # Adjust path if needed\n",
        "\n",
        "    label_col = \"product_category\"\n",
        "    if label_col not in df.columns:\n",
        "        raise KeyError(f\"'{label_col}' column not found in dataset\")\n",
        "\n",
        "    df = df.dropna(subset=[label_col])  # Remove missing labels\n",
        "\n",
        "    # Encode all object columns\n",
        "    label_encoders = {}\n",
        "    for col in df.columns:\n",
        "        if df[col].dtype == 'object':\n",
        "            le = LabelEncoder()\n",
        "            df[col] = le.fit_transform(df[col].astype(str))\n",
        "            label_encoders[col] = le\n",
        "\n",
        "    # Features & labels\n",
        "    X = df.drop(label_col, axis=1)\n",
        "    y = df[label_col]\n",
        "\n",
        "    # ‚úÖ Scale features\n",
        "    scaler = StandardScaler()\n",
        "    X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "    # Split\n",
        "    X_train, X_test, y_train, y_test = train_test_split(\n",
        "        X_scaled, y, test_size=0.2, random_state=42\n",
        "    )\n",
        "\n",
        "    # Train\n",
        "    model = LogisticRegression(max_iter=5000)  # Increased max_iter\n",
        "    model.fit(X_train, y_train)\n",
        "\n",
        "    # Evaluate\n",
        "    y_pred = model.predict(X_test)\n",
        "    print(\"üõçÔ∏è Product Recommendation Model Report:\")\n",
        "    print(classification_report(y_test, y_pred))\n",
        "\n",
        "    # ‚úÖ Save model, scaler, encoders\n",
        "    os.makedirs(\"saved_models\", exist_ok=True)\n",
        "    joblib.dump(model, \"saved_models/product_model.pkl\")\n",
        "    joblib.dump(scaler, \"saved_models/product_scaler.pkl\")\n",
        "    joblib.dump(label_encoders, \"saved_models/product_label_encoders.pkl\")\n",
        "\n",
        "    print(\"‚úÖ Product model trained and saved successfully.\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    train_product_model()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fr5g0Fc70q-u",
        "outputId": "9ede1427-d650-4e42-ea3b-7c90e2ae8314"
      },
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting models/product_model.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python3 models/product_model.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FPSWIk9N60T0",
        "outputId": "fb2bc8a6-643f-4171-aba2-1856a4f11f95"
      },
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üõçÔ∏è Product Recommendation Model Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.10      0.18        10\n",
            "           1       0.29      0.40      0.33         5\n",
            "           2       0.35      0.60      0.44        10\n",
            "           3       0.50      0.43      0.46         7\n",
            "           4       0.33      0.36      0.35        11\n",
            "\n",
            "    accuracy                           0.37        43\n",
            "   macro avg       0.49      0.38      0.35        43\n",
            "weighted avg       0.51      0.37      0.35        43\n",
            "\n",
            "‚úÖ Product model trained and saved successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv(\"/content/drive/MyDrive/merged_engineered_data.csv\")\n",
        "print(df.columns.tolist())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dk7J6O-htlss",
        "outputId": "65b6cf1d-dba1-4f4e-e78a-6a2c031a68b3"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['customer_id_new', 'social_media_platform', 'engagement_score', 'purchase_interest_score', 'review_sentiment', 'customer_id_new_numeric', 'customer_id_legacy', 'transaction_id', 'purchase_amount', 'purchase_date', 'product_category', 'customer_rating', 'purchase_month', 'purchase_day_of_week', 'total_purchase_amount', 'number_of_transactions', 'average_customer_rating']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv(\"image_features.csv\")\n",
        "print(df.columns.tolist())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3YFxBCmc2Geo",
        "outputId": "7719b600-4842-4371-f0b4-29ed343517cb"
      },
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['member_name', 'expression', 'augmentation_type', 'image_path', 'height', 'width', 'aspect_ratio', 'total_pixels', 'blue_mean', 'blue_std', 'blue_min', 'blue_max', 'blue_median', 'green_mean', 'green_std', 'green_min', 'green_max', 'green_median', 'red_mean', 'red_std', 'red_min', 'red_max', 'red_median', 'hue_mean', 'hue_std', 'saturation_mean', 'saturation_std', 'value_mean', 'value_std', 'gray_mean', 'gray_std', 'gray_min', 'gray_max', 'gray_median', 'blue_hist_0', 'blue_hist_1', 'blue_hist_2', 'blue_hist_3', 'blue_hist_4', 'blue_hist_5', 'blue_hist_6', 'blue_hist_7', 'blue_hist_8', 'blue_hist_9', 'blue_hist_10', 'blue_hist_11', 'blue_hist_12', 'blue_hist_13', 'blue_hist_14', 'blue_hist_15', 'green_hist_0', 'green_hist_1', 'green_hist_2', 'green_hist_3', 'green_hist_4', 'green_hist_5', 'green_hist_6', 'green_hist_7', 'green_hist_8', 'green_hist_9', 'green_hist_10', 'green_hist_11', 'green_hist_12', 'green_hist_13', 'green_hist_14', 'green_hist_15', 'red_hist_0', 'red_hist_1', 'red_hist_2', 'red_hist_3', 'red_hist_4', 'red_hist_5', 'red_hist_6', 'red_hist_7', 'red_hist_8', 'red_hist_9', 'red_hist_10', 'red_hist_11', 'red_hist_12', 'red_hist_13', 'red_hist_14', 'red_hist_15', 'gray_hist_0', 'gray_hist_1', 'gray_hist_2', 'gray_hist_3', 'gray_hist_4', 'gray_hist_5', 'gray_hist_6', 'gray_hist_7', 'gray_hist_8', 'gray_hist_9', 'gray_hist_10', 'gray_hist_11', 'gray_hist_12', 'gray_hist_13', 'gray_hist_14', 'gray_hist_15', 'sobel_mean_x', 'sobel_mean_y', 'sobel_std_x', 'sobel_std_y', 'sobel_max_x', 'sobel_max_y', 'edge_density', 'edge_count', 'laplacian_variance', 'num_faces_detected', 'face_x', 'face_y', 'face_width', 'face_height', 'face_area', 'face_aspect_ratio', 'face_center_x', 'face_center_y', 'face_gray_mean', 'face_gray_std', 'face_blue_mean', 'face_blue_std', 'face_green_mean', 'face_green_std', 'face_red_mean', 'face_red_std']\n"
          ]
        }
      ]
    }
  ]
}